{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar o ficheiro\n",
    "df = pd.read_csv('C:\\\\Users\\\\guilh\\\\Desktop\\\\AASE\\\\Projeto\\\\csv\\\\train.csv', sep=\";\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                        #BRAND\n",
    "#Como é possível verificar no gráfico de barras, a maior queda de valores é entre chevrolet para porshe. Portanto, vamos considerar os valores \"Ford\", \"BMW\", \"Mercedes\" e \"Chevorlet\", os outros valores vão ser populados com \"Outro\"\n",
    "allowed_brands = ['Ford', 'Mercedes-Benz', 'BMW', 'Chevrolet']\n",
    "df['brand'] = df['brand'].apply(lambda x: x if x in allowed_brands else 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                        #MODEL\n",
    "#Como vimos na matriz da correlação, a marca não interfere no preço do automóvel, pelo que pode ser removida.\n",
    "#drop the model column\n",
    "df.drop('model', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                        #MODEL_YEAR\n",
    "#Dividimos as datas tipo-  2000-2005 | 2005-2010 ... ?????\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                        #MILAGE\n",
    "#Alterar o tipo da coluna para numero e converter de milhas para kilometros, para melhor compreensão.\n",
    "\n",
    "# Alterar a coluna milage para float e depois converter para km\n",
    "df['milage'] = df['milage'].str.split(\" \", expand = True)[0].str.replace(',', '').astype(float)\n",
    "\n",
    "\n",
    "# converter milhas para kilometros\n",
    "mile_to_km = 0.621371\n",
    "df['kilometers'] = df['milage'] / mile_to_km\n",
    "\n",
    "# Arredondar os valores em 2 casas decimais\n",
    "df['kilometers'] = df['kilometers'].round(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                        #FUEL TYPE\n",
    "\n",
    "# Juntar os hibridos todos, \n",
    "df.loc[df['fuel_type'].str.contains('Hybrid', na=False), 'fuel_type'] = 'Hybrid'\n",
    "df.loc[df['fuel_type'].str.contains('–', na=False), 'fuel_type'] = 'No data'\n",
    "df.loc[df['fuel_type'].str.strip() == '', 'fuel_type'] = 'No data'\n",
    "df.loc[df['fuel_type'] == 'not supported', 'fuel_type'] = 'Hydrogen' # (só existe um carro com este valor: Toyota -Mirai Limited, movido a hidrogénio)\n",
    "# Todos os valores que estão nulos são eletricos\n",
    "df['fuel_type'].fillna('Eletric', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    #ENGINE\n",
    "\n",
    "#Separar os valores do motor em \"Horsepower\", \"Cilinders\" and \"Litres\"\n",
    "split_engine = df['engine'].str.split(' ',expand = True)\n",
    "\n",
    "split_engine.loc[split_engine[0].str.contains('HP'), 'horsepower'] = split_engine.loc[split_engine[0].str.contains('HP'), 0].str.replace('HP', \"\").astype(float)\n",
    "split_engine.loc[(split_engine[0].str.contains('HP')) & (split_engine[1].str.contains('L')), 'litres'] = split_engine.loc[(split_engine[0].str.contains('HP')) & (split_engine[1].str.contains('L')), 1].str.replace('L', \"\").astype(float)\n",
    "split_engine.loc[split_engine[0].str.contains('HP') & (split_engine[3] == 'Cylinder'), 'cylinders'] = split_engine.loc[split_engine[0].str.contains('HP') & (split_engine[3] == 'Cylinder'), 2].str.replace('V', \"\").astype(int)\n",
    "split_engine.loc[split_engine[0].str.contains('HP') & (split_engine[3] == '6'), 'cylinders'] = 6\n",
    "\n",
    "split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[0].str.contains('L')), 'litres'] = pd.to_numeric(split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[0].str.contains('L')), 0].str.replace('L', ''), errors = 'coerce')\n",
    "split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[0].str.contains('V')) & (split_engine['cylinders'].isnull()), 'cylinders'] = abs(pd.to_numeric(split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[0].str.contains('V'))][0].str.replace('V', ''), errors = 'coerce'))\n",
    "\n",
    "\n",
    "split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[1].str.contains('L')), 'litres'] = pd.to_numeric(split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[1].str.contains('L')), 1].str.replace('L', ''), errors = 'coerce')\n",
    "split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[1].str.contains('I')), 'cylinders'] = abs(pd.to_numeric(split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[1].str.contains('I'))][1].str.replace('I', '')))\n",
    "split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[1].str.contains('H')), 'cylinders'] = abs(pd.to_numeric(split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[1].str.contains('H'))][1].str.replace('H', ''), errors = 'coerce'))\n",
    "split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[1].str.contains('W')), 'cylinders'] = abs(pd.to_numeric(split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[1].str.contains('W'))][1].str.replace('W', ''), errors = 'coerce'))\n",
    "split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[1].str.contains('V')), 'cylinders'] = abs(pd.to_numeric(split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[1].str.contains('V'))][1].str.replace('V', ''), errors = 'coerce'))\n",
    "split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[1].isin([str(x) for x in list(range(20))])), 'cylinders'] = split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[1].isin([str(x) for x in list(range(20))]))][1].astype(float)\n",
    "\n",
    "split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[2].str.contains('V')) & (split_engine['cylinders'].isnull()), 'cylinders'] = abs(pd.to_numeric(split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[2].str.contains('V')) & (split_engine['cylinders'].isnull())][2].str.replace('V', '')))\n",
    "split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[2].str.contains('I')) & (split_engine['cylinders'].isnull()), 'cylinders'] = abs(pd.to_numeric(split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[2].str.contains('I')) & (split_engine['cylinders'].isnull())][2].str.replace('I', ''), errors = 'coerce'))\n",
    "split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[2].str.contains('L')) & (split_engine['cylinders'].isnull()), 'litres'] = split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[2].str.contains('L')) & (split_engine['cylinders'].isnull())][2].str.replace('L', '').astype(float)\n",
    "\n",
    "\n",
    "split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[3].str.contains('V')) & (split_engine['cylinders'].isnull()), 'cylinders'] = abs(pd.to_numeric(split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[3].str.contains('V')) & (split_engine['cylinders'].isnull())][3].str.replace('V', ''), errors = 'coerce'))\n",
    "\n",
    "split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[4].str.contains('I')) & (split_engine['cylinders'].isnull()), 'cylinders'] = abs(pd.to_numeric(split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[4].str.contains('I')) & (split_engine['cylinders'].isnull())][4].str.replace('I', ''), errors = 'coerce'))\n",
    "split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[4].str.contains('V')) & (split_engine['cylinders'].isnull()), 'cylinders'] = abs(pd.to_numeric(split_engine.loc[(~split_engine[0].str.contains('HP')) & (split_engine[4].str.contains('V')) & (split_engine['cylinders'].isnull())][4].str.replace('V', ''), errors = 'coerce'))\n",
    "\n",
    "split_engine.loc[(split_engine[1] == 'Liter') & (split_engine['litres'].isnull()), 'litres'] = split_engine.loc[(split_engine[1] == 'Liter') & (split_engine['litres'].isnull())][0].astype(float)\n",
    "\n",
    "df = pd.concat([df, split_engine[['horsepower', 'litres', 'cylinders']]], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "df[['engine', 'horsepower', 'litres', 'cylinders']].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                #ENGINE\n",
    "#substituimos os valores nulos pela media dos valores\n",
    "df['horsepower'].fillna(df['horsepower'].mean(), inplace = True)\n",
    "df['litres'].fillna(df['litres'].mean(), inplace = True)\n",
    "df['cylinders'].fillna(df['cylinders'].mean(), inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSMISSION\n",
    "# Vamos manter apenas \"Automatic\", \"Manual\", \"DCT\", \"No data\"\n",
    "df['transmission'] = df['transmission'].str.lower()\n",
    "\n",
    "df.loc[df['transmission'].str.contains('automatic|a/t|at|auto|cvt'), 'transmission'] = 'Automatic'\n",
    "df.loc[df['transmission'].str.contains('m/t|manual|mt'), 'transmission'] = 'Manual'\n",
    "df.loc[df['transmission'].str.contains('dual shift mode'), 'transmission'] = 'DCT'\n",
    "df.loc[df['transmission'].str.contains('–|2|f|7-speed|variable'), 'transmission'] = 'No data'\n",
    "\n",
    "# Preencher valores nulos com 'No data'\n",
    "df['transmission'].fillna('No data', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                #EXT_COLOR\n",
    "\n",
    "\n",
    "# Substituir 'White' por 'White'\n",
    "df.loc[df['int_col'].str.contains('White', case=False), 'int_col'] = 'White'\n",
    "\n",
    "# Substituir 'black' por 'black'\n",
    "df.loc[df['int_col'].str.contains('Black', case=False), 'int_col'] = 'Black'\n",
    "\n",
    "# Substituir todos os valores que não são \"white\" ou \"black\" por \"other\"\n",
    "df.loc[~df['ext_col'].isin(['White', 'Black']), 'ext_col'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                #INT_COLOR\n",
    "\n",
    "\n",
    "# Substituir os valores baseados em palavras-chave\n",
    "\n",
    "# Substituir 'beige' por 'beige'\n",
    "df.loc[df['int_col'].str.contains('Beige', case=False), 'int_col'] = 'Beige'\n",
    "\n",
    "# Substituir 'black' por 'black'\n",
    "df.loc[df['int_col'].str.contains('Black', case=False), 'int_col'] = 'Black'\n",
    "\n",
    "# Substituir 'gray' por 'gray'\n",
    "df.loc[df['int_col'].str.contains('Gray', case=False), 'int_col'] = 'Gray'\n",
    "\n",
    "# Substituir todos os valores que não são \"white\" ou \"black\" por \"other\"\n",
    "\n",
    "df.loc[~df['int_col'].isin(['Beige', 'Black', \"Gray\"]), 'int_col'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                #CLEAN_TITLE\n",
    "# Substituir os valores ausentes na coluna 'clean_title' por \"No data\"\n",
    "df['clean_title'].fillna(\"No data\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                #ACCIDENT\n",
    "# Substituir os valores ausentes na coluna 'clean_title' por \"No data\"\n",
    "df['accident'].fillna(\"No data\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Seleciona apenas as colunas não numéricas\n",
    "categorical_columns = df.select_dtypes(include='object').columns\n",
    "\n",
    "# Inicializa o LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Mapeia as categorias para números\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Calcule a matriz de correlação de Spearman\n",
    "correlation_matrix = df.corr(method='spearman')\n",
    "\n",
    "# Visualize a matriz de correlação usando um heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlação de Spearman entre Variáveis (Categóricas Mapeadas para Números)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------REMOVER TODAS AS COLUNAS QUE A CORRELAÇÃO COM PREÇO SEJA INFERIOR A 0.5 -----------\n",
    "colunas_para_eliminar = ['cylinders', 'litres', \"clean_title\", \"accident\", \"int_col\", \"ext_col\", \"transmission\", \"engine\", \"fuel_type\", \"milage\", \"brand\" ]\n",
    "# Eliminar as colunas especificadas\n",
    "df = df.drop(colunas_para_eliminar, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "        make_scorer,\n",
    "        confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeRegressor # decision trees for classification\n",
    "from sklearn.naive_bayes import GaussianNB # naive bayes for classification\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC # support vector machines for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "METRICS = {\n",
    "    \"MAE\": make_scorer(mean_absolute_error),\n",
    "    \"MSE\": make_scorer(mean_squared_error),\n",
    "    \"RMSE\": make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred))),\n",
    "    \"R2\": make_scorer(r2_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(\"price\", axis=1), df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Árvores de Decisão\n",
    "dt = DecisionTreeRegressor(max_depth=3, random_state=1234)\n",
    "dt.fit(X, y)  # Treinando o modelo\n",
    "splitter = StratifiedKFold(10, random_state=1234, shuffle=True)\n",
    "scores = cross_validate(dt, X, y, cv=splitter, scoring=METRICS)\n",
    "dt_scores = pd.DataFrame(scores)\n",
    "pd.DataFrame(dt_scores.mean()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NAIVE BAYNES\n",
    "nb = GaussianNB()\n",
    "scores_nb = cross_validate(nb, X, y, cv=splitter, scoring=METRICS)\n",
    "nb.fit(X, y)  # Treinando o modelo\n",
    "nb_scores = pd.DataFrame(scores_nb)\n",
    "pd.DataFrame(nb_scores.mean()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=1234)\n",
    "\n",
    "# Perform cross-validation with the Random Forest Regressor\n",
    "scores_rf = cross_validate(rf, X, y, cv=splitter, scoring=METRICS)\n",
    "\n",
    "# Display the results\n",
    "rf_scores = pd.DataFrame(scores_rf)\n",
    "rf.fit(X, y)  # Treinando o modelo\n",
    "pd.DataFrame(rf_scores.mean()).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VETOR MACHINE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create an SVR model with a pipeline for scaling\n",
    "svr = make_pipeline(StandardScaler(), SVR())\n",
    "\n",
    "# Perform cross-validation with the SVR\n",
    "scores_svr = cross_validate(svr, X, y, cv=splitter, scoring=METRICS)\n",
    "\n",
    "# Display the results\n",
    "svr.fit(X, y)  # Treinando o modelo\n",
    "svr_scores = pd.DataFrame(scores_svr)\n",
    "pd.DataFrame(svr_scores.mean()).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REDES NEURONAIS\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Create an MLP Regressor\n",
    "mlp = MLPRegressor(random_state=1234)\n",
    "\n",
    "# Perform cross-validation with the MLP Regressor\n",
    "scores_mlp = cross_validate(mlp, X, y, cv=splitter, scoring=METRICS)\n",
    "\n",
    "# Display the results\n",
    "mlp_scores = pd.DataFrame(scores_mlp)\n",
    "mlp.fit(X, y)  # Treinando o modelo\n",
    "pd.DataFrame(mlp_scores.mean()).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos e nomes para os gráficos\n",
    "models = [dt, nb, rf, svr, mlp]\n",
    "names = ['Decision Tree', 'Naive Bayes', 'Random Forest', 'SVR', 'Neural Network']\n",
    "\n",
    "# Criando os gráficos de dispersão\n",
    "fig, axes = plt.subplots(5, 1, figsize=(20, 25))\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "\n",
    "for e, ax in enumerate(axes):\n",
    "    model = models[e]\n",
    "\n",
    "    y_pred = model.predict(X)  # Agora, o modelo está treinado\n",
    "\n",
    "    sns.scatterplot(x=y.values.ravel(), y=y_pred.ravel(), ax=ax)\n",
    "    ax.set_title(names[e])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
